#!/usr/bin/env python
'''
Check integrity of record links in airtable export.

First need to run airtable_export.py to export the content from airtable.
This saves the 'bases' dict to a json file.

Examples:
    ./integrity_check.py ../airtable_export/dreq_release_export.json -r v1.2
    ./integrity_check.py ../airtable_export/dreq_raw_export.json
'''
import argparse
import json

def check_aeid(aeid: str, aeid_type: str) -> bool:
    '''
    Return True if input string aeid has the expected format for unique identifiers in an airtable export via pyairtable.
    Example: 'rec00yWOulzoqJuY7' (for a record id string)

    Here "aeid" stands for "airtable export id". This is to avoid confusion with the "uid" stored in data request
    records, which is not generated by airtable.
    '''
    aeid_prefix = {'record': 'rec', 'field': 'fld', 'base': 'app', 'table': 'tbl'}
    prefix = aeid_prefix[aeid_type]
    return isinstance(aeid, str) and aeid.startswith(prefix) and len(aeid) == 17


def main():

    parser = argparse.ArgumentParser(
        description='Simple script to check consistency of links between tables in json file created by airtable_export.py.')
    parser.add_argument('filepath', type=str, help=f'exported content json file to check')
    parser.add_argument('-r', '--release', type=str, default='',
                        help='if this is an official release export, provide the release tag (example: -r v1.0beta)')
    args = parser.parse_args()

    fail_on_uid_check = True
    if args.release == '':
        # raw bases (aka "working bases")
        fail_on_uid_check = False

    filepath = args.filepath
    with open(filepath, 'r') as f:
        bases = json.load(f)
        print(f'Opened {filepath}')

    # Show names of bases, their tables, and number of records in each table
    print(f'\nFound {len(bases)} base')
    print(f'Names of bases and the tables in each base:\n')
    for base_name, tables in bases.items():
        print(f'  {base_name}')
        for table_name, table in tables.items():
            nrec = len(table['records'])
            print(f'    {table_name}  ({nrec} records)')

    # Loop over all records (all tables of all bases) to check:
    # - integrity of record links in each base
    # - uniqueness of uid (unique identifier, example: "3ba74dd0-8ca2-11ef-944e-41a8eb05f654")
    all_uid = set()
    non_unique_uid = set()
    for base_name, tables in bases.items():
        print(f'\nChecking for integrity of exported Airtable base: {base_name}')

        table_id2name = {table['id']: table['name'] for table in tables.values()}  # given table id, look up table name
        n = len(tables)
        assert len(set(table_id2name.keys())) == n, 'table ids are not unique'
        assert len(set(table_id2name.values())) == n, 'table names are not unique'

        # For the tables in this base, check that linked records point to valid records in the indicated linked table
        for table_name, table in tables.items():

            # Make dict with info on fields, indexed by field name (instead of field id)
            fields = {}
            for field in table['fields'].values():
                name = field['name']
                assert name not in fields, f'field names in table {table_name} are not unique: {name}'
                fields[name] = field

            records = table['records']
            for record in records.values():
                for name in record:

                    # Check uniqueness of uid
                    if name.lower() == 'uid':
                        uid = record[name]
                        if uid in all_uid:
                            non_unique_uid.add(uid)
                        else:
                            all_uid.add(uid)

                    field = fields[name]
                    if 'linked_table_id' in field:
                        # This field in the record contains a list of links to records in another table
                        record_links = record[name]  # list of record ids

                        assert isinstance(record_links, list), 'links to other records should be in a list'
                        # if not isinstance(record_links, list):
                        #     print(f'Skipping invalid link in {table_name} for field: {name}')
                        #     continue

                        assert all([check_aeid(aeid, 'record')
                                   for aeid in record_links]), 'unrecognized format for record links'

                        linked_table_name = table_id2name[field['linked_table_id']]
                        for aeid in record_links:
                            assert aeid in tables[linked_table_name]['records'], 'record id not found in linked table'

        # If we've got this far without errors, the export integrity is ok.
        # This means that its database structure is internally consistent (links are not broken, etc.)
        # (It says nothing about the meaning of any of the content!)
        print('  Integrity ok!')

    print(f'\nFound {len(all_uid)} unique identifiers (UID)')
    if len(non_unique_uid) > 0:
        filepath = 'non_unique_uid.txt'
        with open(filepath, 'w') as f:
            f.write('\n'.join(sorted(non_unique_uid)))
        msg = f'{len(non_unique_uid)} of these UIDs were not actually unique!\nWrote ' + filepath
        if fail_on_uid_check:
            raise ValueError(msg)
        else:
            print(msg)
    else:
        print(f'All UIDs were unique')

    # If the following variable names occur, check that they're unique
    check_unique_var_name = []
    check_unique_var_name.append('Compound Name')
    check_unique_var_name.append('CMIP6 Compound Name')
    check_unique_var_name.append('CMIP7 Compound Name')
    # TO DO: add check based on unique name incorporating branded variables if needed

    for unique_var_name in check_unique_var_name:
        # Check uniqueness of variable names
        if args.release == '':
            # raw export
            check_base_tables = {
                'Data Request Variables (Public)': ['Variable'],
                # 'Data Request Opportunities (Public)' : ['Variables']
            }
        else:
            # release export
            check_base_tables = {
                f'Data Request {args.release}': ['Variables'],
            }
        for base_name in check_base_tables:
            print(f'\nChecking uniqueness of "{unique_var_name}" in base: {base_name}')
            for table_name in check_base_tables[base_name]:
                if base_name not in bases:
                    msg = f'Base name not found: "{base_name}"'
                    msg += '\nDoes the release version need to be specified? Invoke with -r option, example: -r v1.2'
                    raise Exception(msg)
                table = bases[base_name][table_name]
                # Get names of all fields in this table
                field_names = [field['name'] for field in table['fields'].values()]
                if unique_var_name in field_names:
                    print(f'  Checking table: {table_name}')
                else:
                    print(f'  "{unique_var_name}" not found in table: {table_name}')
                    continue
                nrec = len(table['records'])
                names = [record[unique_var_name] for record in table['records'].values()]
                print(f'    number of variables: {nrec}')
                n = len(set(names))
                print(f'    number of unique names: {n}')
                if n != nrec:
                    print(f'\n--> "{unique_var_name}" was not unique in base: {base_name}\n')

if __name__ == '__main__':
    main()
